# ğŸ“š LecLens

LecLens is a GenAI-powered platform that transforms lecture videos into interactive, structured learning materials. With just a YouTube link or video upload, users can generate AI-augmented notes, ask timestamped questions, and take quizzes tailored to the content â€” making studying smarter, faster, and more personalized.

![LecLens Banner](link-to-banner-if-you-have-one)

---

## âœ¨ Features

- ğŸ¥ **Video Input**: Upload lecture videos or paste a YouTube link  
- ğŸ“„ **Smart Note Generation**: Auto-summarized, PDF-style structured notes  
- ğŸ¤– **AI-Powered Q&A**: Ask questions and get timestamped answers  
- ğŸ§  **Quiz Generator**: Create MCQs based on the video with difficulty options  
- ğŸ”— **Timestamps**: Clickable links to exact video moments relevant to your question  

---

## ğŸ’¡ Inspiration

Imagine turning your lectures into structured study guides within seconds. LecLens makes video learning more interactive and focused by converting passive watching into active understanding â€” helping students study effectively, anytime, anywhere.

---

## ğŸ§  What It Does

- Accepts lecture input through YouTube links or file uploads
- Uses Whisper for automatic transcription
- Uses Gemini API for smart note summaries, Q&A, and quiz generation
- Displays timestamped answers and contextual insights
- Provides downloadable study materials

---

## ğŸ› ï¸ How We Built It

- **Backend**: Python + Flask for API endpoints and video processing logic
- **Frontend**: Flutter for a modern, responsive user interface
- **AI Integration**:  
  - [Gemini API](https://deepmind.google) for natural language understanding  
  - [Whisper](https://openai.com/research/whisper) for speech-to-text transcription

---

## âš™ï¸ Tech Stack

| Layer        | Tech Used               |
|--------------|--------------------------|
| Frontend     | Flutter                 |
| Backend      | Python, Flask           |
| AI/NLP       | Whisper, Gemini API     |
| Other Tools  | OpenAI APIs, YouTube API |

---

## ğŸ”§ Installation

### ğŸ“‹ Prerequisites

- Python 3.x
- Flutter SDK
- Gemini API Key
- YouTube Data API Key (if using YouTube transcripts)

### â–¶ï¸ Running the Project

**Backend Setup**

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python app.py
```

**Frontend Setup**

```bash
cd frontend/flutter_app
flutter pub get
flutter run -d chrome
```

## ğŸ—‚ï¸ Project Structure
LecLens/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ cache.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â””â”€â”€ endpoints/
â”‚   â”‚       â”œâ”€â”€ notes.py
â”‚   â”‚       â”œâ”€â”€ questions.py
â”‚   â”‚       â”œâ”€â”€ quiz.py
â”‚   â”‚       â””â”€â”€ upload.py
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ llm_wrapper.py
â”‚       â”œâ”€â”€ transcript_extraction.py
â”‚       â”œâ”€â”€ relevant_time_stamps.py
â”‚       â””â”€â”€ youtube_transcript.py
â”‚
â””â”€â”€ frontend/flutter_app/
    â”œâ”€â”€ main.dart
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ button.dart
    â”‚   â”œâ”€â”€ common_background.dart
    â”‚   â””â”€â”€ square_tile.dart
    â”œâ”€â”€ pages/
    â”‚   â””â”€â”€ chat_page.dart
    â””â”€â”€ transcripts/
        â””â”€â”€ transcript_item.dart

## ğŸš§ Challenges We Faced

- Handling noisy or accented speech with Whisper for accurate transcription
- Designing a clean and intuitive UX for users across devices
- Linking AI-generated answers precisely with video timestamps
- Generating meaningful, contextual quiz questions automatically

## ğŸ† Accomplishments

- Successfully combined transcription + NLP for deep video understanding
- Achieved timestamp-linked answers to improve user navigation
- Created customizable quiz generation to support active learning
- Developed a full-stack solution with seamless front-end/back-end integration

## ğŸ“˜ What We Learned

- Leveraged Flutter to build fast, cross-platform UI
- Gained experience integrating large language models with APIs
- Learned to work with video pipelines, timestamps, and speech processing
- Strengthened our ability to design and deliver end-to-end GenAI solutions

## ğŸ”® Whatâ€™s Next

- Enhance transcription quality with speaker diarization and noise filtering
- Improve quiz logic with Bloomâ€™s taxonomy-style difficulty levels
- Add personalized study recommendations and flashcards
- Support collaborative features like shared notes or quizzes
- Expand support to more languages and video sources

## ğŸ¤ Contributing
Want to improve LecLens or suggest new features? Contributions are welcome! Feel free to fork the repo, submit PRs, or open an issue.

## ğŸ“„ License
This project is licensed under the MIT License.

## ğŸ™Œ Acknowledgements

- OpenAI Whisper
- Gemini API
- Flutter
- Python Flask

## ğŸ”— Links
- ğŸ”¬ Demo: [link-to-demo]
- ğŸ“§ Contact: [your-email@example.com]
